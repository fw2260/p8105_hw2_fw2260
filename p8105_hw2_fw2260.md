Homework 2
================
Lily Wang
9/22/2020

This is my solution to Homework 2.

``` r
library(tidyverse)
```

    ## -- Attaching packages ------------------------------- tidyverse 1.3.0 --

    ## v ggplot2 3.3.2     v purrr   0.3.4
    ## v tibble  3.0.3     v dplyr   1.0.2
    ## v tidyr   1.1.2     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0

    ## -- Conflicts ---------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read in and clean the Mr. Trash Wheel dataset:

``` r
trashwheel_df <- 
  read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(round(sports_balls)))
```

Read in and clean the 2017 and 2018 precipitation data:

``` r
precip2017_df <-
  read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)

precip2018_df <-
  read_excel("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)
```

Make a dataframe with month names. Combine the two precipitation
datasets and join the month dataframe with the result:

``` r
month_df <-
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df <-
  bind_rows(precip2017_df, precip2018_df) %>% 
  left_join(., month_df, by = "month") %>% 
  select(year, month_name, total) %>% 
  rename(month = month_name)
```

The Trash Wheel dataset contains information from the Mr. Trash Wheel
trash collector located in Baltimore, MD. The dataset provides
information on year, month, and amount of trash collected, including
specific types of trash. There are a total of 344 rows and 14 columns in
the final dataset. For available data, the total precipitation in 2018
was 70.33 in. The median number of sports balls collected in 2017 was
2.145.

## Problem 2

Read in and clean the NYC Transit dataset:

``` r
nyctransit_df <-
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada) %>% 
  mutate(entry = if_else(entry == "YES", TRUE, FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The NYC Transit dataset contains information such as location, routes
served, entrance type, vending availability, entry allowance, and ADA
compliance for each entrance and exit of each subway station in NYC.

This dataset currently has 1868 rows and 19 columns. There are 465
distinct stations. There are 468 ADA-compliant stations. 69 out of 183
station entrances/exits without vending allow entrance.

This dataset is not tidy yet because all the route variables are in
their own separate columns and should be combined into just two columns,
like this:

``` r
nyctransit_df <-
  nyctransit_df %>% 
  mutate_at(vars(route1:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number")
```

60 distinct stations serve the A train. Of these stations, `r` are
ADA-compliant.

## Problem 3

Import and clean the pols\_month, snp, and unemployment datasets:

``` r
polsmonth_df <-
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year", "month", "day"), "-") %>% 
  mutate(month = as.numeric(month)) %>% 
  left_join(., month_df, by = "month") %>% 
  select(!month) %>%
  relocate(year, month_name, everything()) %>% 
  rename(month = month_name) %>% 
  mutate(
    prez_gop = replace(prez_gop, prez_gop == "1", "gop"),
    prez_dem = replace(prez_dem, prez_dem == "1", "dem")
  ) %>% 
  pivot_longer(
    c(prez_gop, prez_dem),
    values_to = "president"
  ) %>% 
  filter(president != "0") %>% 
  select(!c(day, name)) %>% 
  relocate(year, month, president) %>% 
  arrange(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
snp_df <-
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, c("month", "day", "year"), "/") %>% 
  mutate(month = as.numeric(month)) %>% 
  left_join(., month_df, by = "month") %>% 
  select(!month) %>%
  relocate(year, month_name, everything()) %>% 
  rename(month = month_name) %>% 
  arrange(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
month_df <-
  mutate(month_df, month_abb = str_to_lower(month.abb))

unemployment_df <-
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month_abb",
    values_to = "unemployment_rate"
  ) %>% 
  left_join(., select(month_df, !month), by = "month_abb") %>% 
  select(!month_abb) %>%
  relocate(year, month_name, everything()) %>% 
  rename(month = month_name) %>% 
  arrange(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Now to merge them:
